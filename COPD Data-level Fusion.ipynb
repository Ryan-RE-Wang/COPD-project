{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug 28 09:59:46 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.60.02    Driver Version: 510.60.02    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro RTX 6000     On   | 00000000:1A:00.0 Off |                  Off |\n",
      "| 33%   25C    P8    31W / 260W |      3MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro RTX 6000     On   | 00000000:1C:00.0 Off |                  Off |\n",
      "| 51%   74C    P2   194W / 260W |   4777MiB / 24576MiB |     42%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Quadro RTX 6000     On   | 00000000:1D:00.0 Off |                  Off |\n",
      "| 33%   27C    P8    30W / 260W |      3MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Quadro RTX 6000     On   | 00000000:1E:00.0 Off |                  Off |\n",
      "| 33%   47C    P2   163W / 260W |   4777MiB / 24576MiB |     41%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Quadro RTX 6000     On   | 00000000:3D:00.0 Off |                  Off |\n",
      "| 33%   50C    P2   164W / 260W |   4779MiB / 24576MiB |     41%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Quadro RTX 6000     On   | 00000000:3F:00.0 Off |                  Off |\n",
      "| 33%   27C    P8    20W / 260W |  23786MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Quadro RTX 6000     On   | 00000000:40:00.0 Off |                  Off |\n",
      "| 33%   26C    P8    19W / 260W |  23750MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Quadro RTX 6000     On   | 00000000:41:00.0 Off |                  Off |\n",
      "| 33%   27C    P8    31W / 260W |  23770MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    1   N/A  N/A      7233      C   python                           2387MiB |\n",
      "|    1   N/A  N/A     34508      C   python                           2387MiB |\n",
      "|    3   N/A  N/A     20876      C   python                           2387MiB |\n",
      "|    3   N/A  N/A     40398      C   python                           2387MiB |\n",
      "|    4   N/A  N/A     27971      C   python                           2387MiB |\n",
      "|    4   N/A  N/A     59993      C   python                           2387MiB |\n",
      "|    5   N/A  N/A      2228      C   ...conda/envs/gpu/bin/python    23783MiB |\n",
      "|    6   N/A  N/A      2228      C   ...conda/envs/gpu/bin/python    23747MiB |\n",
      "|    7   N/A  N/A      2228      C   ...conda/envs/gpu/bin/python    23767MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:7', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from Parse_TFrecords import *\n",
    "from define_model import *\n",
    "from load_label import *\n",
    "from utilities import *\n",
    "import gc\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, average_precision_score\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \n",
    "print(gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for class 0: 0.61\n",
      "Weight for class 1: 2.88\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# All\n",
    "# pos = 57925\n",
    "# neg = 212124\n",
    "\n",
    "# Emory\n",
    "pos = 25294\n",
    "neg = 120259\n",
    "\n",
    "# MIMIC\n",
    "# pos = 32631\n",
    "# neg = 91865\n",
    "\n",
    "total = pos+neg\n",
    "\n",
    "weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint Data Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_file_train = 'tfrecords/copd_emory_train.tfrecords'\n",
    "train_dataset = (tf.data.TFRecordDataset(\n",
    "    record_file_train, buffer_size=BATCH_SIZE, compression_type=None, num_parallel_reads=32)\n",
    ".map(parse_TFrecord_demo)\n",
    ".shuffle(BATCH_SIZE)\n",
    ".batch(BATCH_SIZE))\n",
    "\n",
    "record_file_val = 'tfrecords/copd_emory_val.tfrecords'\n",
    "val_dataset = (tf.data.TFRecordDataset(\n",
    "    record_file_val, buffer_size=BATCH_SIZE, compression_type=None, num_parallel_reads=32)\n",
    ".map(parse_TFrecord_demo)\n",
    ".batch(BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'checkpoints_fusion/checkpoint_Xception'\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min')\n",
    "\n",
    "callback = [tf.keras.callbacks.LearningRateScheduler(scheduler),\n",
    "            tf.keras.callbacks.EarlyStopping(mode='min', patience=3, monitor='val_loss'),\n",
    "            model_checkpoint_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4549/4549 [==============================] - 1395s 305ms/step - loss: 0.6227 - auc: 0.6974 - val_loss: 0.6054 - val_auc: 0.7491\n",
      "Epoch 2/5\n",
      "4549/4549 [==============================] - 1456s 320ms/step - loss: 0.5804 - auc: 0.7468 - val_loss: 0.6218 - val_auc: 0.7520\n",
      "Epoch 3/5\n",
      "2545/4549 [===============>..............] - ETA: 9:14 - loss: 0.5436 - auc: 0.7777"
     ]
    }
   ],
   "source": [
    "model = get_model_demo()\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                 optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), metrics='AUC')\n",
    "\n",
    "model.fit(train_dataset, epochs=5, shuffle=True, validation_data=val_dataset, callbacks=callback, class_weight=class_weight)\n",
    "\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "record_file_test = 'tfrecords/copd_emory_test.tfrecords'\n",
    "test_dataset = (tf.data.TFRecordDataset(\n",
    "    record_file_test, buffer_size=BATCH_SIZE, compression_type=None, num_parallel_reads=32)\n",
    ".map(parse_TFrecord_demo)\n",
    ".batch(BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model_demo()\n",
    "\n",
    "model.load_weights(checkpoint_filepath)\n",
    "\n",
    "y_label, y_demo = get_data_label('emory', split, True)\n",
    "\n",
    "y_preds = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = get_thresh(y_label, y_preds, 'Youden')\n",
    "\n",
    "test_CI(y_preds, y_label, thresh)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Source Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_file_train = 'tfrecords/copd_merged_train.tfrecords'\n",
    "train_dataset = (tf.data.TFRecordDataset(\n",
    "    record_file_train, buffer_size=BATCH_SIZE, compression_type=None, num_parallel_reads=32)\n",
    ".map(parse_TFrecord_train)\n",
    ".shuffle(BATCH_SIZE)\n",
    ".batch(BATCH_SIZE))\n",
    "\n",
    "record_file_val = 'tfrecords/copd_merged_val.tfrecords'\n",
    "val_dataset = (tf.data.TFRecordDataset(\n",
    "    record_file_val, buffer_size=BATCH_SIZE, compression_type=None, num_parallel_reads=32)\n",
    ".map(parse_TFrecord_train)\n",
    ".batch(BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archi = 'Xception'\n",
    "checkpoint_filepath = 'checkpoints_merged/checkpoint_BCE_{i}'.format(i=archi)\n",
    "monitor_ = 'val_loss'\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    monitor=monitor_,\n",
    "    mode='min')\n",
    "\n",
    "callback = [tf.keras.callbacks.LearningRateScheduler(scheduler),\n",
    "            tf.keras.callbacks.EarlyStopping(mode='min', patience=3, monitor=monitor_),\n",
    "            model_checkpoint_callback]\n",
    "\n",
    "model = get_model_demo(archi)\n",
    "\n",
    "loss_func = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(loss=loss_func,\n",
    "                 optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), metrics='AUC')\n",
    "\n",
    "model.fit(train_dataset, epochs=5, shuffle=True, validation_data=val_dataset, callbacks=callback, class_weight=class_weight)\n",
    "\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "record_file_test = 'tfrecords/copd_emory_test.tfrecords'\n",
    "test_dataset = (tf.data.TFRecordDataset(\n",
    "    record_file_test, buffer_size=BATCH_SIZE, compression_type=None, num_parallel_reads=32)\n",
    ".map(parse_TFrecord_demo)\n",
    ".batch(BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'checkpoints_merged/checkpoint_BCE_{i}'.format(i=archi)\n",
    "\n",
    "model = define_model()\n",
    "\n",
    "model.load_weights(checkpoint_filepath)\n",
    "\n",
    "y_label, y_demo = get_data_label('merged', split, True)\n",
    "\n",
    "y_preds = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = get_thresh(y_label, y_preds, 'Youden')\n",
    "\n",
    "test_CI(y_preds, y_label, thresh)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_list = ['White', 'Black', 'Latino', 'Others', 'Asian']\n",
    "\n",
    "for race_num, race in enumerate(race_list):\n",
    "    print(race)\n",
    "    \n",
    "    idx = []\n",
    "    for i, l in enumerate(y_demo):\n",
    "        if (l['Race']==race_num):\n",
    "            idx.append(i)\n",
    "            \n",
    "    temp_df = y_preds[idx]\n",
    "    temp_label = y_label[idx]\n",
    "    \n",
    "    thresh = get_thresh(temp_label, temp_df, 'Youden')\n",
    "\n",
    "    test_CI(temp_df, temp_label, thresh)\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_list = ['Female', 'Male']\n",
    "\n",
    "for gender_num, gender in enumerate(gender_list):\n",
    "    print(gender)\n",
    "    \n",
    "    idx = []\n",
    "    for i, l in enumerate(y_demo):\n",
    "        if (l['Gender']==gender_num):\n",
    "            idx.append(i)\n",
    "\n",
    "    temp_df = y_preds[idx]\n",
    "    temp_label = y_label[idx]\n",
    "    \n",
    "    thresh = get_thresh(temp_label, temp_df, 'Youden')\n",
    "\n",
    "    test_CI(temp_df, temp_label, thresh)\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_list = ['0-40', '40-60', '60-80', '80-']\n",
    "\n",
    "for age_num, age in enumerate(age_list):\n",
    "    print(age)\n",
    "    \n",
    "    idx = []\n",
    "    for i, l in enumerate(y_demo):\n",
    "        if (l['Age']==age_num):\n",
    "            idx.append(i)\n",
    "\n",
    "    temp_df = y_preds[idx]\n",
    "    temp_label = y_label[idx]\n",
    "    \n",
    "    thresh = get_thresh(temp_label, temp_df, 'Youden')\n",
    "\n",
    "    test_CI(temp_df, temp_label, thresh)\n",
    "\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hitienv",
   "language": "python",
   "name": "hitienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
