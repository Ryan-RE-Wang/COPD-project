{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-creature",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from GradCAM import *\n",
    "from define_model import *\n",
    "from load_data import *\n",
    "from utilities import *\n",
    "from Parse_TFrecords import *\n",
    " \n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"cpu:0\"): \n",
    "    checkpoint_filepath = 'checkpoints/AUC/checkpoint_BCE_Dnet121'\n",
    "    archi = 'Dnet121'\n",
    "    model = define_model(archi)\n",
    "    model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-innocent",
   "metadata": {},
   "source": [
    "# GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-circuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"cpu:0\"): \n",
    "    last_conv_layer_name = 'relu'\n",
    "    classifier_layer_names = ['max_pool', 'dense']\n",
    "\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer\n",
    "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
    "    last_conv_layer_model = tf.keras.Model(model.inputs, last_conv_layer.output)\n",
    "\n",
    "    # Second, we create a model that maps the activations of the last conv\n",
    "    # layer to the final class predictions\n",
    "    classifier_input = tf.keras.Input(shape=last_conv_layer.output.shape[1:])\n",
    "    x = classifier_input\n",
    "    for layer_name in classifier_layer_names:\n",
    "        x = model.get_layer(layer_name)(x)\n",
    "    classifier_model = tf.keras.Model(classifier_input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-tolerance",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_file_test = 'copd_test_new.tfrecords'\n",
    "test_dataset = (tf.data.TFRecordDataset(\n",
    "    record_file_test, buffer_size=256, compression_type=None, num_parallel_reads=32)\n",
    ".map(parse_TFrecord_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_map = []\n",
    "preds = []\n",
    "img = []\n",
    "with tf.device(\"cpu:0\"): \n",
    "    for i, l in test_dataset:\n",
    "        if (l == 1):\n",
    "            img_array = np.reshape(i, (1, 256, 256, 3))\n",
    "            pred = model.predict(img_array)\n",
    "            if(pred >= 0.9):\n",
    "                img.append(img_array)\n",
    "                heat_map.append(show_heatmap(img_array, last_conv_layer_model, classifier_model))\n",
    "                preds.append(pred)\n",
    "                \n",
    "    preds = np.array(preds).reshape(len(preds,))\n",
    "    order = np.argsort(np.array(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-sociology",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in order[-20:]:\n",
    "    plt.imshow(np.reshape(heat_map[i], (256, 256, 3)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-republican",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_heatmap = np.mean(heat_map, axis=0)\n",
    "plt.imshow(np.reshape(mean_heatmap, (256, 256, 3)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-samoa",
   "metadata": {},
   "source": [
    "# Saliency map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-journalist",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"cpu:0\"):\n",
    "    def get_saliency_map(model, image):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(image)\n",
    "            loss = model(image)\n",
    "                        \n",
    "        # Get the gradients of the loss w.r.t to the input image.\n",
    "        gradient = tape.gradient(loss, image)\n",
    "                \n",
    "        dgrad_abs = tf.math.abs(gradient)\n",
    "#         print(dgrad_abs.shape)\n",
    "        dgrad_max_ = np.max(dgrad_abs, axis=-1)[0]\n",
    "#         print(dgrad_max_.shape)\n",
    "\n",
    "        # normaliz between 0 and 1\n",
    "        arr_min, arr_max  = np.min(dgrad_max_), np.max(dgrad_max_)\n",
    "        smap = (dgrad_max_ - arr_min) / (arr_max - arr_min + 1e-18)\n",
    "\n",
    "        return smap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-malpractice",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.device(\"cpu:0\"):\n",
    "    linear_model = tf.keras.Model(inputs=model.input, outputs=model.layers[-1].output)\n",
    "    for i in order[-20:]:\n",
    "        print(preds[i])\n",
    "        smap = get_saliency_map(linear_model, tf.Variable(img[i], dtype=float))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(img[i][0])\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(smap, cmap='Reds')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"cpu:0\"):\n",
    "    smaps = []\n",
    "    for i in range(len(img)):\n",
    "        smaps.append(get_saliency_map(linear_model, tf.Variable(img[i], dtype=float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-expression",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_img = np.mean(img, axis=0)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(mean_img[0], cmap='gray')\n",
    "\n",
    "mean_smap = np.mean(smaps, axis=0)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(mean_smap, cmap='Reds')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
